{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c74b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import math\n",
    "import requests\n",
    "import os.path\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from os import path\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc77a7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_BASE = ('http://nas.er.usgs.gov/api/v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fa0c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def api_df(species_id, limit, api_key):\n",
    "#Returns a pandas dataframe containing records about a species from the NAS database using their API#\n",
    "    \n",
    "    # Check for API key\n",
    "    if api_key is not None:\n",
    "        url_request = f\"{URL_BASE}/occurrence/search?species_ID={species_id}&api_key={api_key}\"\n",
    "    else:\n",
    "        url_request = f\"{URL_BASE}/occurrence/search?species_ID={species_id}\"\n",
    "    \n",
    "    # Get dataframe from API request\n",
    "    request_json = requests.get(url_request, params={'limit':limit}).json()\n",
    "    api_df = pd.json_normalize(request_json, 'results')\n",
    "    api_df = _manage_cols(api_df)\n",
    "\n",
    "    # Add columns that are in a CSV dataframe but not an API dataframe\n",
    "    api_df['country']      = np.nan\n",
    "    api_df['drainagename'] = np.nan\n",
    "\n",
    "    # Rename columns\n",
    "    renamed_columns = _get_col_rename(api_df, 'api')\n",
    "    api_df = api_df.rename(columns=renamed_columns)\n",
    "\n",
    "    # Reorder columns\n",
    "    cols = list(api_df.columns)\n",
    "    cols = cols[0:8] + cols[33:34] + cols[8:33] + cols[34:] # country\n",
    "    cols = cols[0:16] + cols[34:] + cols[16:34] # drainagename\n",
    "    api_df = api_df[cols]\n",
    "    \n",
    "    return api_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d34f450",
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_df(filename):\n",
    "    #\"\"\"Returns a pandas dataframe containing records about a species from the NAS database using a downloaded CSV file\"\"\"\n",
    "\n",
    "    # Get dataframe from CSV file\n",
    "    csv_df = pd.read_csv(filename, low_memory=False)\n",
    "\n",
    "    csv_df = _manage_cols(csv_df)\n",
    "    \n",
    "    # Add columns that are in an API dataframe but not a CSV dataframe\n",
    "    csv_df['centroidtype'] = np.nan\n",
    "    csv_df['date']         = np.nan\n",
    "    csv_df['genus']        = np.nan\n",
    "    csv_df['huc10name']    = np.nan\n",
    "    csv_df['huc10']        = np.nan\n",
    "    csv_df['huc12name']    = np.nan\n",
    "    csv_df['huc12']        = np.nan\n",
    "    csv_df['huc8name']     = np.nan\n",
    "    csv_df['species']      = np.nan\n",
    "\n",
    "    # Rename columns so both csv and api dataframes have identical headers\n",
    "    renamed_columns = _get_col_rename(csv_df, 'csv')\n",
    "    csv_df = csv_df.rename(columns=renamed_columns)\n",
    "    \n",
    "    # Reorder columns\n",
    "    cols = list(csv_df.columns)\n",
    "    cols = cols[:4] + cols[69:70] + cols[75:76] + cols[4:69] + cols[70:75] # species and genus\n",
    "    cols = cols[:17] + cols[69:70] + cols[17:69] + cols[70:] # centroidtype\n",
    "    cols = cols[:18] + cols[75:] + cols[18:75] # huc8name\n",
    "    cols = cols[:20] + cols[72:] + cols[20:72] # huc10name, huc10, huc12name, huc12\n",
    "    cols = cols[:24] + cols[75:] + cols[24:75] # date\n",
    "    csv_df = csv_df[cols]\n",
    "\n",
    "    # Change reference columns to single reference column\n",
    "    csv_df = _convert_refs(csv_df)\n",
    "    \n",
    "    return csv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b919ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_df(df, keep=None, drop=None, rename=None, refs=None, earth=False):\n",
    "    \"\"\"Returns a dataframe that has altered columns (dropped, renamed), is filtered for a subset of references, and is compatible with Google Earth Engine import\"\"\"\n",
    "    \n",
    "    df_dict = {}\n",
    "    drop_list = []\n",
    "\n",
    "    if drop and keep:\n",
    "        if set(list(df.columns)) == set(drop + keep):\n",
    "            drop_list = drop\n",
    "        else:\n",
    "            raise ValueError(f\"Drop column list and keep column list do not combine to make set of all columns\")\n",
    "    elif drop:\n",
    "        drop_list = drop\n",
    "    elif keep:\n",
    "        drop_list = np.setdiff1d(list(df.columns), keep)\n",
    "\n",
    "    if earth:\n",
    "        if rename and ( 'latitude' in list(rename.keys()) or 'longitude' in list(rename.keys()) ):\n",
    "            raise ValueError(\"Can't rename latitude or longitude when Google Earth Engine import compatibility is true\")\n",
    "        # Create compatible date column\n",
    "        df = _make_date_col(df)\n",
    "    \n",
    "    if refs:\n",
    "        df = df[df.astype(str)['references'] != '[]']\n",
    "        df['ref_key'] = df.references.map(lambda x: x[0]['key'])\n",
    "        df = df[df.ref_key.isin(refs)]\n",
    "        df = df.drop('ref_key', axis = 1)\n",
    "    \n",
    "    df_out = _manage_cols(df, drop_list, df_dict)\n",
    "\n",
    "    return df_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e67cb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_out(df, filepath='./', filename=None, overwrite=False):\n",
    "    \"\"\"Creates a CSV file using a generated name based on species and references, optionally overwriting or using a custom filename\"\"\"\n",
    "    \n",
    "    if filename == None:\n",
    "        # Create generated filename\n",
    "        filename = ''\n",
    "        if 'commonname' in list(df.columns):\n",
    "            filename += (df.iloc[0].commonname).lower().replace(' ','')\n",
    "        else:\n",
    "            filename += str(datetime.now())\n",
    "    else:\n",
    "        # TODO: Check if filename is good\n",
    "        pass\n",
    "\n",
    "    if overwrite == False:\n",
    "        # Check if filename already exists\n",
    "        filenumber = 0\n",
    "        while path.exists(filepath + filename + str(filenumber)):\n",
    "            filenumber += 1\n",
    "        filename += f\"_{filenumber}\"\n",
    "    \n",
    "    df.to_csv(filepath + filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30ff6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_header():\n",
    "    \"\"\"Returns a list of strings corresponding to the column names for occurrence queries\"\"\"\n",
    "    str_list = ['specimennumber','speciesid','group','family','genus','species','scientificname', \\\n",
    "                'commonname','country','state','county','locality','latitude','longitude', \\\n",
    "                'source','accuracy','drainagename','centroidtype','huc8name','huc8', \\\n",
    "                'huc10name','huc10','huc12name','huc12','date','year','month','day','status','comments', \\\n",
    "                'recordtype','disposal','museumcatnumber','freshmarineintro','references']\n",
    "    return str_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d9ef67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def species(genus, species, output='list'):\n",
    "    \"\"\"Returns NAS query results for a binomial name. Output is either a string or a list of references\"\"\"\n",
    "    url_request_species = f\"{URL_BASE}/species/search?genus={genus}&species={species}\"\n",
    "    request_result = requests.get(url_request_species).json()\n",
    "    species_list = request_result['results']\n",
    "\n",
    "    if output == 'string':\n",
    "        species_str = \"\"\n",
    "        for species in species_list:\n",
    "            for value in species:\n",
    "                species_str += f\"{value}: {species[value]}\\n\"\n",
    "            species_str += '\\n'\n",
    "        return species_str\n",
    "    elif output == 'list':\n",
    "        return species_list\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid parameter for output '{output}' - Accepted values are 'list' or 'string'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c325c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def references(df, sort='rank', ascending=True, output='list', limit=-1):\n",
    "    \"\"\"Returns a list of references for a dataframe. Sorts by alphabet or rank, in ascending or descending order.\n",
    "    Output is either in a string or a list of references.\"\"\"\n",
    "    \n",
    "    ref_counts = list(df['references'].value_counts().items())\\\n",
    "\n",
    "    if output == 'string':\n",
    "        ref_string = \"\"\n",
    "        if sort == 'rank':\n",
    "            if ascending:\n",
    "                ref_number = 1\n",
    "            else:\n",
    "                ref_number = len(ref_counts) + 1\n",
    "            for ref_pair in ref_counts:\n",
    "                if (ascending == True) and (limit != -1) and (ref_number > limit):\n",
    "                    break\n",
    "                elif (ascending == False) and (limit != -1) and (ref_number < (len(ref_counts) + 1 - limit)):\n",
    "                    break\n",
    "                ref_string +=  '--------\\n'\n",
    "                ref_string += f\"Most common reference {ref_number}\\n\"\n",
    "                ref_string += '\\n'\n",
    "                source_number = 1\n",
    "                for ref in ref_pair[0]:\n",
    "                    ref_string += f\"Source number:      {source_number}\\n\"\n",
    "                    ref_string += f\"Title:              {ref['title']}\\n\"\n",
    "                    ref_string += f\"Author:             {ref['author']}\\n\"\n",
    "                    ref_string += f\"Publisher:          {ref['publisher']}\\n\"\n",
    "                    ref_string += f\"Publisher Location: {ref['publisherLocation']}\\n\"\n",
    "                    ref_string += f\"Year:               {ref['year']}\\n\"\n",
    "                    ref_string += f\"Reference Type:     {ref['refType']}\\n\"\n",
    "                    ref_string += f\"Reference Key:      {ref['key']}\\n\"\n",
    "                    ref_string += '\\n'\n",
    "                    source_number += 1\n",
    "                ref_string +=     f\"Total Occurrences:  {ref_pair[1]}\\n\"\n",
    "                ref_string += '--------\\n'\n",
    "                ref_string += '\\n'\n",
    "                if ascending: \n",
    "                    ref_number += 1\n",
    "                else:\n",
    "                    ref_number -= 1\n",
    "        elif sort == 'alphabet':\n",
    "            # TODO: alphabetical sorting\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid parameter for sort '{sort}' - Accepted values are 'rank' or 'alphabet'\")\n",
    "        return ref_string\n",
    "    elif output == 'list':\n",
    "        return ref_counts\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid parameter for output '{output}' - Accepted values are 'list' or 'string'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba257de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_col_rename(df, dftype):\n",
    "    \"\"\"Returns a dictionary of columns to rename based on the dataframe and type('csv' or 'api')\"\"\"\n",
    "    \n",
    "    # Build a dictionary of column renamings for use in pandas rename function\n",
    "    renamed_columns = {}\n",
    "    column_names = list(df.columns)\n",
    "    lower_columns = [name.lower().replace(' ','').replace('_','') for name in column_names]\n",
    "    for i in range(len(column_names)):\n",
    "        renamed_columns[column_names[i]] = lower_columns[i]\n",
    "\n",
    "    if dftype == 'csv':\n",
    "        # build csv rename dictionary\n",
    "        renamed_columns['museumcatno'] = 'museumcatnumber'\n",
    "        renamed_columns['huc8number']  = 'huc8'\n",
    "    elif dftype == 'api':\n",
    "        # build api rename dictionary\n",
    "        renamed_columns['key']              = 'specimennumber'\n",
    "        renamed_columns['decimallatitude']  = 'latitude'\n",
    "        renamed_columns['decimallongitude'] = 'longitude'\n",
    "        renamed_columns['latlongsource']    = 'source'\n",
    "        renamed_columns['latlongaccuracy']  = 'accuracy'\n",
    "    else:\n",
    "        raise ValueError(f\"Dataframe type '{dftype}' invalid - Accepted inputs are 'csv' or 'api'\")\n",
    "\n",
    "    return renamed_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c79a0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _convert_refs(df):\n",
    "    drop_list = []\n",
    "\n",
    "    # Always remove the separate reference fields\n",
    "    for i in range(6):\n",
    "        drop_list.append(f\"reference{i+1}\")\n",
    "        drop_list.append(f\"type{i+1}\")\n",
    "        drop_list.append(f\"date{i+1}\")\n",
    "        drop_list.append(f\"author{i+1}\")\n",
    "        drop_list.append(f\"title{i+1}\")\n",
    "        drop_list.append(f\"publisher{i+1}\")\n",
    "        drop_list.append(f\"location{i+1}\")\n",
    "\n",
    "    # Convert separate reference fields into a list of reference dictionaries\n",
    "    # This is for compatibility with NAS API dataframes\n",
    "    ref_list_of_lists = [None] * len(df)\n",
    "    i = 0\n",
    "    for row in df.itertuples():\n",
    "        ref_list = []\n",
    "        for j in range(6):\n",
    "            # For each reference section in row, build a dict and add it to the list of dicts\n",
    "            ref_dict = {}\n",
    "            # Convert key and date to integer instead of float if existent\n",
    "            ref_dict['key'] = int(row[35 + j * 7]) if not math.isnan(row[35 + j * 7]) else math.nan\n",
    "            if not math.isnan(ref_dict['key']):\n",
    "                ref_dict['refType']           = row[36 + j * 7]\n",
    "                ref_dict['year']              = int(row[37 + j * 7]) if not math.isnan(row[37 + j * 7]) else math.nan\n",
    "                ref_dict['author']            = row[38 + j * 7]\n",
    "                ref_dict['title']             = row[39 + j * 7]\n",
    "                ref_dict['publisher']         = row[40 + j * 7]\n",
    "                ref_dict['publisherLocation'] = row[41 + j * 7]\n",
    "                ref_list.append(ref_dict)\n",
    "            else:\n",
    "                break\n",
    "        ref_list_of_lists[i] = ref_list\n",
    "        i += 1\n",
    "\n",
    "    # Add reference column and drop unwanted columns, rename\n",
    "    df['references'] = ref_list_of_lists\n",
    "    df = df.drop(drop_list, axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098749ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_date_col(df):\n",
    "    df = df.fillna(1)\n",
    "    df['date'] = pd.to_datetime(df.year*10000 + df.month*100 + df.day, format='%Y%m%d')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9437a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _manage_cols(df, drop_list=[], name_dict={}):\n",
    "    \"\"\"Private method for dropping and renaming columns in a dataframe, as well as creating one standard table from two different forms.\"\"\"\n",
    "\n",
    "    for colname in drop_list:\n",
    "        if colname not in df:\n",
    "            raise ValueError(f\"Can't drop column '{colname}' - '{colname}' does not exist in dataframe\")\n",
    "    for colname in list(name_dict.keys()):\n",
    "        if colname not in df:\n",
    "            raise ValueError(f\"Can't rename '{colname}' to '{name_dict[colname]}' - '{colname}' does not exist in dataframe\")\n",
    "        if colname in drop_list:\n",
    "            raise ValueError(f\"Can't rename '{colname}' to '{name_dict[colname]}' - '{colname}' in drop_list\")\n",
    "\n",
    "    column_names = np.setdiff1d(list(df.columns), list(name_dict.keys()))\n",
    "    lower_columns = [name.lower().replace(' ','').replace('_','') for name in column_names]\n",
    "    for i in range(len(column_names)):\n",
    "        name_dict[column_names[i]] = lower_columns[i]\n",
    "    \n",
    "    df = df.drop(drop_list, axis=1)\n",
    "    df = df.rename(columns=name_dict)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12408f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ea004b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
